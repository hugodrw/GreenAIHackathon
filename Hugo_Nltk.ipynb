{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "l3nefHlKWpow"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Imports"
      ],
      "metadata": {
        "id": "l3nefHlKWpow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "o5OwGB1s3azF",
        "outputId": "f92b94eb-2dc1-428c-b3eb-0cb95ba058c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-48eae2c3a0cb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stopwords'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nltk' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_path = 'gdrive/My Drive/Hackathon_2023/' # To be adapted by the user"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPbsUGk_Whg-",
        "outputId": "2376a8de-4fc9-497d-a808-dc6b755a8c17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yk2teRAiWMFJ",
        "outputId": "6c34b667-ef51-44c0-c425-cbe3861e3e65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting prettyprinter\n",
            "  Downloading prettyprinter-0.18.0-py2.py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 kB\u001b[0m \u001b[31m395.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from prettyprinter) (2.16.1)\n",
            "Collecting colorful>=0.4.0 (from prettyprinter)\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: colorful, prettyprinter\n",
            "Successfully installed colorful-0.5.5 prettyprinter-0.18.0\n"
          ]
        }
      ],
      "source": [
        "import datetime\n",
        "import gensim.downloader\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow\n",
        "\n",
        "from lxml import etree\n",
        "!pip install prettyprinter\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "from nltk import tokenize\n",
        "from numpy.random import seed as numpy_seed\n",
        "from prettyprinter import pprint\n",
        "from sklearn.metrics import classification_report\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, TimeDistributed, Dense\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Dataset"
      ],
      "metadata": {
        "id": "3a_hO_SHakAl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(root_path + \"train.csv\")"
      ],
      "metadata": {
        "id": "2vp62_YvanjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_data.text\n",
        "y_train = train_data.label"
      ],
      "metadata": {
        "id": "82GzFcvRa469"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_word_tokenized = X_train.apply(word_tokenize)\n",
        "X_train_sent_tokenized = X_train.apply(sent_tokenize)"
      ],
      "metadata": {
        "id": "LfDEpn6JbO5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_word_tokenized.iloc[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwNCuCuTobu2",
        "outputId": "993dbe6a-0c57-4748-dfa1-89f526de3fc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This',\n",
              " 'movie',\n",
              " 'is',\n",
              " 'a',\n",
              " 'journey',\n",
              " 'through',\n",
              " 'the',\n",
              " 'mind',\n",
              " 'of',\n",
              " 'a',\n",
              " 'screenwriter',\n",
              " 'caught',\n",
              " 'in',\n",
              " 'his',\n",
              " 'own',\n",
              " 'paradoxical',\n",
              " 'philosophy',\n",
              " '.',\n",
              " 'He',\n",
              " 'examines',\n",
              " 'the',\n",
              " 'ever',\n",
              " 'illusive',\n",
              " 'question',\n",
              " 'of',\n",
              " \"'who\",\n",
              " 'am',\n",
              " 'I',\n",
              " \"'\",\n",
              " 'and',\n",
              " \"'what\",\n",
              " 'is',\n",
              " 'I',\n",
              " '?',\n",
              " \"'\",\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'a',\n",
              " 'courageous',\n",
              " 'and',\n",
              " 'thought',\n",
              " 'provoking',\n",
              " 'enterprise',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'shipload',\n",
              " 'of',\n",
              " 'beautiful',\n",
              " 'images',\n",
              " ',',\n",
              " 'dream-inspired',\n",
              " ',',\n",
              " 'Escher-like',\n",
              " 'paradoxes',\n",
              " 'reminiscent',\n",
              " 'of',\n",
              " 'the',\n",
              " 'hand',\n",
              " 'drawing',\n",
              " 'itself',\n",
              " ',',\n",
              " 'or',\n",
              " 'rather',\n",
              " ',',\n",
              " 'erasing',\n",
              " 'itself',\n",
              " '.',\n",
              " 'More',\n",
              " 'and',\n",
              " 'more',\n",
              " 'we',\n",
              " 'follow',\n",
              " 'the',\n",
              " 'writer',\n",
              " 'in',\n",
              " 'his',\n",
              " 'agony',\n",
              " 'over',\n",
              " 'what',\n",
              " 'to',\n",
              " 'say',\n",
              " 'and',\n",
              " 'what',\n",
              " 'to',\n",
              " 'film',\n",
              " ',',\n",
              " 'we',\n",
              " 'see',\n",
              " 'him',\n",
              " 'phoning',\n",
              " 'with',\n",
              " 'his',\n",
              " 'wife',\n",
              " 'who',\n",
              " 'left',\n",
              " 'for',\n",
              " 'Peru',\n",
              " ',',\n",
              " 'leaving',\n",
              " 'him',\n",
              " 'to',\n",
              " 'take',\n",
              " 'care',\n",
              " 'of',\n",
              " 'their',\n",
              " 'baby',\n",
              " ',',\n",
              " 'a',\n",
              " 'task',\n",
              " 'he',\n",
              " 'performs',\n",
              " 'with',\n",
              " 'less',\n",
              " 'and',\n",
              " 'less',\n",
              " 'attention',\n",
              " 'until',\n",
              " 'he',\n",
              " \"'s\",\n",
              " 'so',\n",
              " 'absorbed',\n",
              " 'in',\n",
              " 'his',\n",
              " 'dilemma',\n",
              " \"'s\",\n",
              " 'that',\n",
              " 'he',\n",
              " 'hardly',\n",
              " 'looks',\n",
              " 'at',\n",
              " 'the',\n",
              " 'child',\n",
              " 'anymore',\n",
              " '.',\n",
              " 'His',\n",
              " 'wife',\n",
              " 'comes',\n",
              " 'back',\n",
              " 'and',\n",
              " 'makes',\n",
              " 'a',\n",
              " 'scene',\n",
              " ',',\n",
              " 'destroys',\n",
              " 'his',\n",
              " 'notes',\n",
              " 'and',\n",
              " 'helping',\n",
              " 'him',\n",
              " 'go',\n",
              " 'over',\n",
              " 'the',\n",
              " 'last',\n",
              " 'treshold',\n",
              " 'until',\n",
              " 'he',\n",
              " 'erases',\n",
              " 'him-self',\n",
              " '.',\n",
              " 'Interspersed',\n",
              " 'with',\n",
              " 'eye-pleasing',\n",
              " 'and',\n",
              " 'I-destructing',\n",
              " 'images',\n",
              " ',',\n",
              " 'the',\n",
              " 'story',\n",
              " 'is',\n",
              " 'mainly',\n",
              " 'philosophical',\n",
              " '.',\n",
              " 'It',\n",
              " \"'s\",\n",
              " 'about',\n",
              " 'the',\n",
              " 'veils',\n",
              " 'of',\n",
              " 'Maya',\n",
              " ',',\n",
              " 'the',\n",
              " 'world',\n",
              " 'of',\n",
              " 'illusion',\n",
              " '.',\n",
              " 'The',\n",
              " 'paradox',\n",
              " 'of',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'however',\n",
              " ',',\n",
              " 'is',\n",
              " 'that',\n",
              " 'it',\n",
              " 'needs',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'talking',\n",
              " 'and',\n",
              " 'thinking',\n",
              " 'to',\n",
              " 'prove',\n",
              " 'that',\n",
              " 'thinking',\n",
              " 'should',\n",
              " 'stop',\n",
              " '.',\n",
              " 'During',\n",
              " 'the',\n",
              " 'more',\n",
              " 'than',\n",
              " 'two',\n",
              " 'hours',\n",
              " 'of',\n",
              " 'provocative',\n",
              " 'beauty',\n",
              " 'and',\n",
              " 'rapid',\n",
              " 'philosophising',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'made',\n",
              " 'me',\n",
              " 'long',\n",
              " 'for',\n",
              " 'silence',\n",
              " 'or',\n",
              " 'a',\n",
              " 'shorter',\n",
              " 'movie',\n",
              " '.',\n",
              " 'If',\n",
              " 'that',\n",
              " 'was',\n",
              " 'the',\n",
              " 'purpose',\n",
              " 'of',\n",
              " 'the',\n",
              " 'maker',\n",
              " ',',\n",
              " 'he',\n",
              " 'succeeded',\n",
              " 'quite',\n",
              " 'well',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_sent_tokenized.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oa1TS4FXowXK",
        "outputId": "72505c6c-3fcb-4742-9274-eca25e6eee70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [This movie is a journey through the mind of a...\n",
              "1    ['Water' (2005), the final part of Toronto-bas...\n",
              "2    [This, which was shown dubbed in Italian at a ...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim"
      ],
      "metadata": {
        "id": "4ygaf5HJvW8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_test = set(list(gensim.downloader.info()['models'].keys()))"
      ],
      "metadata": {
        "id": "U0dMWZq9xBUj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def out_of_vocabulary(embeddings_model, X_train_word_tokenized):\n",
        "  oovs = []\n",
        "  tokens = []\n",
        "  for review in X_train_word_tokenized:\n",
        "    for token in review:\n",
        "      if token not in tokens:\n",
        "        tokens.append(token)\n",
        "      try:\n",
        "        embedding = embeddings_model[token]\n",
        "      except KeyError:\n",
        "        if token not in oovs:\n",
        "          oovs.append(token)\n",
        "\n",
        "    count_token = len(tokens)\n",
        "    count_oov = len(oovs)\n",
        "\n",
        "    result = count_oov/count_token\n",
        "    return result"
      ],
      "metadata": {
        "id": "VfW9eF3TyCn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_to_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDGgaUX_xFe7",
        "outputId": "775886d6-3384-4e2b-9e22-da8dc742eddf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'__testing_word2vec-matrix-synopsis',\n",
              " 'conceptnet-numberbatch-17-06-300',\n",
              " 'fasttext-wiki-news-subwords-300',\n",
              " 'glove-twitter-100',\n",
              " 'glove-twitter-200',\n",
              " 'glove-twitter-25',\n",
              " 'glove-twitter-50',\n",
              " 'glove-wiki-gigaword-100',\n",
              " 'glove-wiki-gigaword-200',\n",
              " 'glove-wiki-gigaword-300',\n",
              " 'glove-wiki-gigaword-50',\n",
              " 'word2vec-google-news-300',\n",
              " 'word2vec-ruscorpora-300'}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model = gensim.downloader.load('glove-twitter-25')\n",
        "score_oov = out_of_vocabulary(embeddings_model,X_train_word_tokenized)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kITmNhijyFpr",
        "outputId": "7f43f068-4db2-4367-fb65-f099dc1b2271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model50 = gensim.downloader.load('glove-twitter-50')\n",
        "score_oov50 = out_of_vocabulary(embeddings_model50,X_train_word_tokenized)"
      ],
      "metadata": {
        "id": "NhSGhl3qMHBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score_oov50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bARE_ny1spE",
        "outputId": "7a7a1ee2-832e-49bd-bedf-7fddfee9446e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.15862068965517243"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model['hello','hello']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX_Uo-WpxdS6",
        "outputId": "1839bcd6-7050-427f-b575-82e3d198c071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.77069  ,  0.12827  ,  0.33137  ,  0.0050893, -0.47605  ,\n",
              "       -0.50116  ,  1.858    ,  1.0624   , -0.56511  ,  0.13328  ,\n",
              "       -0.41918  , -0.14195  , -2.8555   , -0.57131  , -0.13418  ,\n",
              "       -0.44922  ,  0.48591  , -0.6479   , -0.84238  ,  0.61669  ,\n",
              "       -0.19824  , -0.57967  , -0.65885  ,  0.43928  , -0.50473  ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "xYklTI1NMKiq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "vectors_per_line = []\n",
        "\n",
        "# Iterate through each line in X_train_word_tokenized\n",
        "for line in X_train_word_tokenized:\n",
        "    # Initialize a list to store the word vectors for this line\n",
        "    line_vectors = []\n",
        "\n",
        "    # For each word in the line, get its word vector if available\n",
        "    for word in line:\n",
        "        if word in embeddings_model:\n",
        "            word_vector = embeddings_model[word]\n",
        "            line_vectors.append(word_vector)\n",
        "\n",
        "    # Append the list of word vectors for this line to the overall list\n",
        "    vectors_per_line.append(line_vectors)"
      ],
      "metadata": {
        "id": "AAb9wf0L-45T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b15bbb9f-b27f-49e9-c223-7ad50feef4d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 17 s, sys: 672 ms, total: 17.7 s\n",
            "Wall time: 17.9 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_vectors = []\n",
        "\n",
        "# Iterate through the list of word vectors for each line\n",
        "for line_vectors in vectors_per_line:\n",
        "    # Check if there are word vectors for this line\n",
        "    if line_vectors:\n",
        "        # Calculate the average word vector for this line\n",
        "        avg_vector = np.mean(line_vectors, axis=0)\n",
        "        average_vectors.append(avg_vector)\n",
        "    else:\n",
        "        # If there are no word vectors for the line, you can add a placeholder vector or handle it as needed\n",
        "        # For example, you can add a vector of zeros as a placeholder\n",
        "        avg_vector = np.zeros(embeddings_model.vector_size)\n",
        "        average_vectors.append(avg_vector)"
      ],
      "metadata": {
        "id": "O50wUcHo_t5v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(average_vectors)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YH4TynRhArms",
        "outputId": "b3caf028-6526-4863-e208-551924852a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30000"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_vectors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQR8Hm4jQyyU",
        "outputId": "912f9d8b-c5d5-49c5-e5bd-5c1145e1e1fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4272937e-02,  5.4409574e-03,  4.0613063e-02,  1.2869835e-01,\n",
              "       -1.6128452e-01,  7.1491026e-03,  1.0654520e+00, -1.4623122e-01,\n",
              "       -2.0290756e-01, -8.6695023e-02, -3.2035378e-03,  2.6582807e-01,\n",
              "       -4.4781170e+00,  9.8431386e-02,  1.5041010e-01,  4.1246057e-02,\n",
              "        1.4566056e-01, -4.5048822e-02, -1.7163524e-01, -3.1990290e-01,\n",
              "       -9.7695217e-02,  1.5836792e-01, -1.7303239e-01, -4.6207208e-02,\n",
              "       -3.0433354e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "03AvTP8NCJ67"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "average_vectors = np.array(average_vectors)\n",
        "average_vectors[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sQIqATuUa6k",
        "outputId": "bfc44cbe-4f40-4b24-f30b-3de579ec2b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4272937e-02,  5.4409574e-03,  4.0613063e-02,  1.2869835e-01,\n",
              "       -1.6128452e-01,  7.1491026e-03,  1.0654520e+00, -1.4623122e-01,\n",
              "       -2.0290756e-01, -8.6695023e-02, -3.2035378e-03,  2.6582807e-01,\n",
              "       -4.4781170e+00,  9.8431386e-02,  1.5041010e-01,  4.1246057e-02,\n",
              "        1.4566056e-01, -4.5048822e-02, -1.7163524e-01, -3.1990290e-01,\n",
              "       -9.7695217e-02,  1.5836792e-01, -1.7303239e-01, -4.6207208e-02,\n",
              "       -3.0433354e-01], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_vectors = np.array(average_vectors)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(average_vectors, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the logistic regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "\n",
        "# Define the hyperparameter grid to search over\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
        "    'penalty': ['l1', 'l2'],  # Regularization type\n",
        "    'max_iter': [100, 1000, 10000]  # Maximum number of iterations\n",
        "}\n",
        "\n",
        "# Create a GridSearchCV object\n",
        "grid_search = GridSearchCV(estimator=logistic_regression, param_grid=param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit the model with grid search to find the best parameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best parameters and the corresponding accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_model = grid_search.best_estimator_\n",
        "test_accuracy = best_model.score(X_test, y_test)\n",
        "print(\"Test Set Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "TjqFSkJ3C89k",
        "outputId": "a300b708-c99b-41a2-e58d-8185ddfa7542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-117690f41d53>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Split the data into training and testing sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the logistic regression model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2557\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"At least one array required as input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2559\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2561\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    398\u001b[0m             \u001b[0;34m\"Found input variables with inconsistent numbers of samples: %r\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;34m%\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [30000, 24000]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib"
      ],
      "metadata": {
        "id": "ufCNV5EAGEHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(best_model, 'hugo_v1.pkl')"
      ],
      "metadata": {
        "id": "wkcNrtSyGI7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5a0d34-4525-4c0d-8717-b9fd113ea40e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hugo_v1.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    }
  ]
}